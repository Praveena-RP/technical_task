Title
 This repository contains python scripts and datasets for tasks related to natural language processing and data analysis,including dataset cleaning and language model subtask processing.
 Description:
   This project focuses on NLP and data analysis using python.it consists of multiple subtasks aimed at cleaning,analyzing, and processing text data with specific objectives for each subtask.The key goal of this project is to apply ML and NLP techniques to Perform Sentimental analysis based on the article content.
Subtasks
  Task1: Data Cleaning and Preprocessing
    This subtask involves cleaning raw data by handling missing values,removing duplicates,and performing basic NLP preprocessing like tokenization. The cleaned data is saved as cleaned_data.csv for further analysis.
  Task2: NLP Feature Extraction
   The NLP_subtask2.py script extracts key NLP features such as named entities and key phrases from the preprocessed data. It uses popular NLP libraries for tokenization, stemming, and feature extraction.
Subtask 3: Language Model Processing
   The LLM_subtask3.py script focuses on language model tasks such as fine-tuning pre-trained models, making predictions, and evaluating NLP tasks using transformer models and deep learning techniques.
Imported Libraries
   Several Python libraries are used in this project for various NLP, machine learning, and data processing tasks:

      pandas: Used for data manipulation and analysis, especially for handling CSV files (data loading, cleaning, and exporting).
      numpy: Used for numerical operations and array manipulations.
      nltk: A comprehensive library for NLP tasks, including tokenization, stop word removal, stemming, and other text processing utilities.
      transformers: Used for working with pre-trained models like BERT, GPT, etc., to perform language model-related tasks (fine-tuning, text generation, etc.).
      sklearn (scikit-learn): Provides tools for machine learning algorithms like classification, clustering, and model evaluation metrics.
      matplotlib / seaborn: Used for data visualization, generating graphs and plots to showcase insights.
      re (Regular Expressions): Used for advanced text preprocessing tasks like cleaning and pattern matching within the text.
      Selenium: Automates browser actions to interact with websites and scrape dynamic content.
      WebDriver: Works with browsers like Chrome or Firefox to automate web-based tasks.
Results
  cleaned_data.csv: Cleaned and preprocessed dataset.
  analyzed_data.csv: Dataset with additional analysis and insights.
